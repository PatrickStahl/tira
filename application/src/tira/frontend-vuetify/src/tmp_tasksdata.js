export function getTasksData() {
  return [
    {
      "task_id":"archive-query-log",
      "task_name":"Archive Query Log",
      "task_description":"The Archive Query Log is a comprehensive query log collected at the Internet Archive over the last 25 years. This version includes 357 million queries, 306 million search result pages, and 2.6 billion search results across 550 search providers. TIRA allows to run arbitrary software on this dataset in a privacy preserving way: the results of executed software is blinded until they reviewed (both the output, and the software) to ensure that no sensitive data is leaked. \n\n\nTo start developing your approach, please look at the corresponding gihub repository (with a small sample dataset to show the structure and also all required code): https://github.com/webis-de/archive-query-log",
      "organizer":"Webis",
      "organizer_id":"webis",
      "web":"https://github.com/webis-de/archive-query-log",
      "year":"2022",
      "featured":true,
      "require_registration":false,
      "require_groups":false,
      "restrict_groups":false,
      "allowed_task_teams":"",
      "master_vm_id":"princess-knight",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":1,
      "software_count":0,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2023,
      "dataset_first_created":2023,
      "dataset_last_modified":"2023-02-21"
    },
    {
      "task_id":"author-diarization",
      "task_name":"Author Diarization",
      "task_description":"Given a document, identify and group text fragments that correspond to individual authors.",
      "organizer":"PAN",
      "organizer_id":"pan",
      "web":"http://pan.webis.de",
      "year":"2012-2021",
      "featured":false,
      "require_registration":false,
      "require_groups":false,
      "restrict_groups":false,
      "allowed_task_teams":"",
      "master_vm_id":"pan15-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":6,
      "software_count":53,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2016,
      "dataset_first_created":2016,
      "dataset_last_modified":"2016-03-08"
    },
    {
      "task_id":"author-masking",
      "task_name":"Author Masking",
      "task_description":"Given a document, paraphrase it so that its writing style does not match that of its original author, anymore.",
      "organizer":"PAN",
      "organizer_id":"pan",
      "web":"http://pan.webis.de",
      "year":"2012-2021",
      "featured":false,
      "require_registration":false,
      "require_groups":false,
      "restrict_groups":false,
      "allowed_task_teams":"",
      "master_vm_id":"pan15-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":2,
      "software_count":39,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2016,
      "dataset_first_created":2016,
      "dataset_last_modified":"2016-02-17"
    },
    {
      "task_id":"author-profiling",
      "task_name":"Author Profiling",
      "task_description":"Given a document, your task is to determine its author's age and gender.",
      "organizer":"PAN",
      "organizer_id":"pan",
      "web":"http://pan.webis.de",
      "year":"2012-2021",
      "featured":false,
      "require_registration":false,
      "require_groups":false,
      "restrict_groups":false,
      "allowed_task_teams":"",
      "master_vm_id":"pan15-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":50,
      "software_count":1066,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2020,
      "dataset_first_created":2014,
      "dataset_last_modified":"2017-04-30"
    },
    {
      "task_id":"authorship-attribution",
      "task_name":"Authorship Attribution",
      "task_description":"Given documents from a set of candidate authors and a \"questioned\" document, the task is to determine whether the questioned document was written by one of the candidate authors.",
      "organizer":"PAN",
      "organizer_id":"pan",
      "web":"http://pan.webis.de",
      "year":"2012-2021",
      "featured":false,
      "require_registration":false,
      "require_groups":false,
      "restrict_groups":false,
      "allowed_task_teams":"",
      "master_vm_id":"pan15-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":26,
      "software_count":137,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2019,
      "dataset_first_created":2015,
      "dataset_last_modified":"2015-10-20"
    },
    {
      "task_id":"authorship-verification",
      "task_name":"Authorship Verification",
      "task_description":"Given a set of \"known\" documents by a single author and a \"questioned\" document, the task is to determine whether the questioned document was written by the same author who wrote the known document set.",
      "organizer":"PAN",
      "organizer_id":"pan",
      "web":"http://pan.webis.de",
      "year":"2012-2021",
      "featured":false,
      "require_registration":false,
      "require_groups":false,
      "restrict_groups":false,
      "allowed_task_teams":"",
      "master_vm_id":"pan20-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":132,
      "software_count":296,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2020,
      "dataset_first_created":2013,
      "dataset_last_modified":"2016-09-03"
    },
    {
      "task_id":"bo-grundlagen-der-regelungstechnik-ss2022",
      "task_name":"BO Grundlagen der Regelungstechnik SS2022",
      "task_description":"Open Modelica",
      "organizer":"Webis",
      "organizer_id":"webis",
      "web":"https://www.hochschule-bochum.de/die-bo/hochschule/campus-velbert-heiligenhaus/studieren-am-cvh/lehrveranstaltungen/",
      "year":"2022",
      "featured":false,
      "require_registration":false,
      "require_groups":false,
      "restrict_groups":false,
      "allowed_task_teams":"",
      "master_vm_id":"sharki-bo-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":1,
      "software_count":3,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"",
      "command_description":"",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2022,
      "dataset_first_created":2022,
      "dataset_last_modified":"2022-06-03"
    },
    {
      "task_id":"buw-nlp-course-summer-term-2022",
      "task_name":"NLP@BUW - Summer Term 2022",
      "task_description":"This task has all the datasets for the 5 Shared Tasks used in the lab class of the course 'Introduction to Natural Language Processing' at Bauhaus University Weimar.",
      "organizer":"Webis",
      "organizer_id":"webis",
      "web":"https://www.uni-weimar.de/en/media/chairs/computer-science-department/webis/teaching/ss-2022/natural-language-processing/",
      "year":"2022",
      "featured":false,
      "require_registration":false,
      "require_groups":false,
      "restrict_groups":false,
      "allowed_task_teams":"",
      "master_vm_id":"nlptasks-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":6,
      "software_count":19,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2022,
      "dataset_first_created":2022,
      "dataset_last_modified":"2022-07-12"
    },
    {
      "task_id":"celebrity-profiling",
      "task_name":"Celebrity Profiling",
      "task_description":"Given the English Social Media feed of a celebrity, determine their degree of fame, occupation, age, and gender.",
      "organizer":"PAN",
      "organizer_id":"pan",
      "web":"http://pan.webis.de",
      "year":"2012-2021",
      "featured":false,
      "require_registration":false,
      "require_groups":false,
      "restrict_groups":false,
      "allowed_task_teams":"",
      "master_vm_id":"pan15-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":5,
      "software_count":86,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2020,
      "dataset_first_created":2019,
      "dataset_last_modified":"2019-01-31"
    },
    {
      "task_id":"chat-analytics-for-twitch",
      "task_name":"Chat Analytics for Twitch",
      "task_description":"Given a user's chat history in a Twitch channel, determine the subscription status.",
      "organizer":"ECML/PKDD",
      "organizer_id":"ecml20",
      "web":"https://events.professor-x.de/dc-ecmlpkdd-2020/",
      "year":"2020",
      "featured":false,
      "require_registration":false,
      "require_groups":false,
      "restrict_groups":false,
      "allowed_task_teams":"",
      "master_vm_id":"chat20-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":2,
      "software_count":22,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2020,
      "dataset_first_created":2020,
      "dataset_last_modified":"2020-03-24"
    },
    {
      "task_id":"clickbait-detection",
      "task_name":"Clickbait Detection",
      "task_description":"Develop a classifier that rates how click baiting a social media post is.",
      "organizer":"Clickbait Challenge",
      "organizer_id":"clickbait-challenge",
      "web":"http://www.clickbait-challenge.org/",
      "year":"2017-2021",
      "featured":false,
      "require_registration":false,
      "require_groups":false,
      "restrict_groups":false,
      "allowed_task_teams":"",
      "master_vm_id":"clickbait17-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":7,
      "software_count":117,
      "max_std_out_chars_on_test_data":100,
      "max_std_err_chars_on_test_data":100,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2020,
      "dataset_first_created":2017,
      "dataset_last_modified":"2017-07-20"
    },
    {
      "task_id":"clickbait-spoiling",
      "task_name":"Clickbait Challenge at SemEval 2023 - Clickbait Spoiling",
      "task_description":"Clickbait posts link to web pages and advertise their content by arousing curiosity instead of providing informative summaries. Clickbait spoiling aims at generating short texts that satisfy the curiosity induced by a clickbait post.",
      "organizer":"PAN",
      "organizer_id":"pan",
      "web":"https://pan.webis.de/semeval23/pan23-web/clickbait-challenge.html",
      "year":"2012-2021",
      "featured":false,
      "require_registration":true,
      "require_groups":true,
      "restrict_groups":true,
      "allowed_task_teams":"princess-knight\npan23-diane-simmons\npan23-francis-wilde\npan23-monique-marmelstein\npan23-alexander-knox\npan23-posh279\npan23-perry-white\npan23-chick-adams\npan23-miranda-priestly\nmachamp\npan23-john-larsen\npan23-christine-massey\npan23-walter-burns\npan23-vic-sage\npan23-hal-towne\npan23-kate-ripperton\nadam-maclean\npan23-billy-batson\nben-andrews\nrick-jason\npan23-king-of-code\npan23-brooke-english\namy-amanda-allen\nart-donovan\nbillie-newman\nbryan-denton\nclark-kent\ncy-bennett\ndx-beaumont\nemily-cowles\nfrankly-unctuous\ngallegher\nharris-claibourne\njack-deveraux\njack-flood\nduke-william\npan23-snapper-carr\njack-ryder\nsteve-martin\njohn-boy-walton\njohn-king\njonah-jameson\npan23-sam-miller\nkat-grant\nkermit-the-frog\nklugie\nlou-sheldon\nmark-markin\nmatt-bai\nmiles-clarkson\nmorbo-the-annihilator\nmr-fosdick\nmr-wallace\nmurray-scarvi\ncarrie-bradshaw\nnick-alexander\npaul-morgan\npaul-templin\nrobin-scherbatsky\nsabrina-spellman\nspider-jerusalem\nstephen-colbert\nsweet-polly-purebred\nted-baxter\ntom-bradford\ntom-tucker\ntony-vincenzo\ntrinity-wells\ntrudy-monk\nvicki-vale\nsocial-media-ie\nnancy-hicks-gribble\nscott-norris\num6p-cs\ndave-tabak\nrory-gilmore",
      "master_vm_id":"clickbait-spoiling-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":4,
      "software_count":9,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware --input $inputDataset/input.jsonl --output $outputDir/run.jsonl",
      "command_description":"Your software has to read \u003Ccode\u003E$inputDataset/input.jsonl\u003C/code\u003E and write to \u003Ccode\u003E$outputDir/run.jsonl\u003C/code\u003E \u003Ca href=\"https://pan.webis.de/semeval23/pan23-web/clickbait-challenge.html#software-submission\" target=\"_blank\"\u003E[detailed instructions]\u003C/a\u003E",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2022,
      "dataset_first_created":2022,
      "dataset_last_modified":"2022-11-15"
    },
    {
      "task_id":"discourse-relation-sense-classification",
      "task_name":"Discourse Relation Sense Classification",
      "task_description":"Given the argument pairs and explicit discourse connectives (and raw text), your task is to identify the senses of the given discourse relations. The task is available in both Chinese and English in 2016.",
      "organizer":"CoNLL",
      "organizer_id":"conll",
      "web":"http://www.cs.brandeis.edu/~clp/conll15st/",
      "year":"2015-2018",
      "featured":false,
      "require_registration":false,
      "require_groups":false,
      "restrict_groups":false,
      "allowed_task_teams":"",
      "master_vm_id":"conll15-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":19,
      "software_count":74,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":100,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2016,
      "dataset_first_created":2015,
      "dataset_last_modified":"2015-03-04"
    },
    {
      "task_id":"dogument-retirever",
      "task_name":"Dogument_Retriever",
      "task_description":"Information retrieval SS23 lab project",
      "organizer":"Dogument_Retriever",
      "organizer_id":"dogument-retriever",
      "web":"",
      "year":"2023",
      "featured":false,
      "require_registration":false,
      "require_groups":false,
      "restrict_groups":false,
      "allowed_task_teams":"",
      "master_vm_id":"princess-knight",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":0,
      "software_count":0,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":"",
      "dataset_first_created":"",
      "dataset_last_modified":""
    },
    {
      "task_id":"dscscdcs",
      "task_name":"dscscdcs",
      "task_description":"dsds",
      "organizer":"basfasdfadfas",
      "organizer_id":"basfasdfadfas",
      "web":"https://sdsds",
      "year":"asdfasdas",
      "featured":false,
      "require_registration":false,
      "require_groups":false,
      "restrict_groups":false,
      "allowed_task_teams":"",
      "master_vm_id":"princess-knight",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":0,
      "software_count":0,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":"",
      "dataset_first_created":"",
      "dataset_last_modified":""
    },
    {
      "task_id":"hyperpartisan-news-detection",
      "task_name":"Hyperpartisan News Detection",
      "task_description":"Given a news article text, decide whether it follows a hyperpartisan argumentation, i.e., whether it exhibits blind, prejudiced, or unreasoning allegiance to one party, faction, cause, or person.",
      "organizer":"PAN",
      "organizer_id":"pan",
      "web":"https://pan.webis.de/semeval19/semeval19-web/",
      "year":"2012-2021",
      "featured":false,
      "require_registration":false,
      "require_groups":false,
      "restrict_groups":false,
      "allowed_task_teams":"",
      "master_vm_id":"semeval-pan-2019-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":11,
      "software_count":474,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2019,
      "dataset_first_created":2018,
      "dataset_last_modified":"2018-08-31"
    },
    {
      "task_id":"ir-benchmarks",
      "task_name":"ir-benchmarks",
      "task_description":"A collection of information retrieval benchmarks covering 15 corpora (1.9 billion documents) on which 32 well-known shared tasks are based.\nWe filled the leaderboards with Docker images of 50 standard retrieval approaches.\nWithin this setup, we were able to automatically run and evaluate the 50 approaches on the 32 tasks (1600 runs).\n\n\nAll Benchmarks are added as training datasets because their qrels are already publicly available.\n\nPlease find a detailed tutorial on how to submit approaches at https://github.com/tira-io/ir-experiment-platform/tree/main/tira-ir-starters",
      "organizer":"Webis",
      "organizer_id":"webis",
      "web":"https://github.com/tira-io/ir-experiment-platform/",
      "year":"2022",
      "featured":false,
      "require_registration":true,
      "require_groups":true,
      "restrict_groups":true,
      "allowed_task_teams":"tira-ir-starter\nows",
      "master_vm_id":"princess-knight",
      "is_ir_task":false,
      "irds_re_ranking_image":"webis/tira-application:0.0.36",
      "irds_re_ranking_command":"/irds_cli.sh --input_dataset_directory $inputDataset --output_dataset_path $outputDir --rerank $inputRun",
      "irds_re_ranking_resource":"irds-data-mounted",
      "dataset_count":31,
      "software_count":0,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2023,
      "dataset_first_created":2023,
      "dataset_last_modified":"2023-02-11"
    },
    {
      "task_id":"ir-convention-test",
      "task_name":"ir-convention-test",
      "task_description":"TBD: Internal by Maik Fr\u00f6be (A)",
      "organizer":"Webis",
      "organizer_id":"webis",
      "web":"https://test",
      "year":"2022",
      "featured":false,
      "require_registration":true,
      "require_groups":true,
      "restrict_groups":true,
      "allowed_task_teams":"test-1-on-17-2022\ntest-2-on-17-2022\ntest-3-on-17-2022\ntest-4-on-17-2022\ntest-5-on-17-2022\ntest-6-on-17-2022",
      "master_vm_id":"princess-knight",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":23,
      "software_count":9,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2023,
      "dataset_first_created":2022,
      "dataset_last_modified":"2023-04-23"
    },
    {
      "task_id":"ir-lab-jena-leipzig-sose-2023",
      "task_name":"IR Lab Jena/Leipzig SoSe 2023",
      "task_description":"The lab for the information retrieval exercise in sommer semester 2023.",
      "organizer":"ir-lab-sose23",
      "organizer_id":"ir-lab-sose23",
      "web":"https://temir.org/teaching/information-retrieval-ss23/ information-retrieval-ss23.html",
      "year":"2023",
      "featured":false,
      "require_registration":true,
      "require_groups":true,
      "restrict_groups":true,
      "allowed_task_teams":"ir-lab-sose-2023-tutors\nir-lab-sose-2023-test-1\nir-lab-sose-2023-test-2",
      "master_vm_id":"princess-knight",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":0,
      "software_count":0,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":"",
      "dataset_first_created":"",
      "dataset_last_modified":""
    },
    {
      "task_id":"mlbuw-winter-term-2022",
      "task_name":"ML@BUW - Winter Term 2022",
      "task_description":"This task has all the datasets for the Shared Tasks used in the lab class of the course 'Introduction to Machine Learning' at Bauhaus Universit\u00e4t Weimar.",
      "organizer":"Webis",
      "organizer_id":"webis",
      "web":"https://www.uni-weimar.de/en/media/chairs/computer-science-department/webis/teaching/ws-202223/machine-learning/",
      "year":"2022",
      "featured":false,
      "require_registration":true,
      "require_groups":true,
      "restrict_groups":true,
      "allowed_task_teams":"buw-ml22-00\nbuw-ml22-01\nbuw-ml22-02\nbuw-ml22-03\nbuw-ml22-04\nbuw-ml22-05\nbuw-ml22-07\nbuw-ml22-09\nbuw-ml22-10\nbuw-ml22-11\nbuw-ml22-12\nbuw-ml22-13\nbuw-ml22-14\nbuw-ml22-15\nbuw-ml22-16\nbuw-ml22-17\nbuw-ml22-20\nbuw-ml22-23\nbuw-ml22-27\nbuw-ml22-28\nbuw-ml22-30\nbuw-ml22-31\nbuw-ml22-32\nbuw-ml22-33\nbuw-ml22-35\nbuw-ml22-36\nbuw-ml22-42\nbuw-ml22-45\nbuw-ml22-49\nbuw-ml22-50\nbuw-ml22-55\nbuw-ml22-60\nbuw-ml22-64\nbuw-ml22-69",
      "master_vm_id":"nlptasks-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":3,
      "software_count":0,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2022,
      "dataset_first_created":2022,
      "dataset_last_modified":"2022-11-11"
    },
    {
      "task_id":"nlpbuw-summer-term-2023",
      "task_name":"NLP@BUW - Summer Term 2023",
      "task_description":"This task has all the datasets for the 5 Shared Tasks used in the lab class of the course 'Introduction to Natural Language Processing' at Bauhaus University Weimar.",
      "organizer":"Webis",
      "organizer_id":"webis",
      "web":"https://www.uni-weimar.de/en/media/chairs/computer-science-department/webis/teaching/ss-2023/",
      "year":"2022",
      "featured":false,
      "require_registration":true,
      "require_groups":true,
      "restrict_groups":true,
      "allowed_task_teams":"nlp23-baselines\nnlp23-bert\nnlp23-bloom\nnlp23-chinchilla\nnlp23-claude\nnlp23-ernie\nnlp23-galactica\nnlp23-glam\nnlp23-gopher\nnlp23-gpt\nnlp23-lamda\nnlp23-llama\nnlp23-luminous\nnlp23-megatron\nnlp23-minerva\nnlp23-opt\nnlp23-palm\nnlp23-roberta\nnlp23-sydney\nnlp23-yalm",
      "master_vm_id":"princess-knight",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":2,
      "software_count":0,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2023,
      "dataset_first_created":2023,
      "dataset_last_modified":"2023-04-12"
    },
    {
      "task_id":"nlpfsu-summer-term-2023",
      "task_name":"NLP@FSU - Summer Term 2023",
      "task_description":"This task consists of two datasets, causal relation detection and causal relation extraction. They are used in the lab class of the NLP course at the FSU during the summer semester 2023.",
      "organizer":"Webis",
      "organizer_id":"webis",
      "web":"",
      "year":"2022",
      "featured":false,
      "require_registration":false,
      "require_groups":false,
      "restrict_groups":false,
      "allowed_task_teams":"",
      "master_vm_id":"princess-knight",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":1,
      "software_count":0,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2023,
      "dataset_first_created":2023,
      "dataset_last_modified":"2023-04-13"
    },
    {
      "task_id":"pan21-authorship-verification",
      "task_name":"Authorship Verification 2021",
      "task_description":"Given two texts, determine if they are written by the same author.  The test dataset contains verification cases from previously unseen authors and topics.",
      "organizer":"PAN",
      "organizer_id":"pan",
      "web":"https://pan.webis.de/clef21/pan21-web/author-identification.html",
      "year":"2012-2021",
      "featured":false,
      "require_registration":false,
      "require_groups":false,
      "restrict_groups":false,
      "allowed_task_teams":"",
      "master_vm_id":"pan21-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":1,
      "software_count":120,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2021,
      "dataset_first_created":2021,
      "dataset_last_modified":"2021-04-30"
    },
    {
      "task_id":"pan21-profiling-hate-speech-spreaders-on-twitter",
      "task_name":"Profiling Hate Speech Spreaders on Twitter",
      "task_description":"Given a Twitter feed, determine whether its author spreads hate speech.",
      "organizer":"PAN",
      "organizer_id":"pan",
      "web":"https://pan.webis.de/clef21/pan21-web/author-profiling.html",
      "year":"2012-2021",
      "featured":false,
      "require_registration":false,
      "require_groups":false,
      "restrict_groups":false,
      "allowed_task_teams":"",
      "master_vm_id":"pan21-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":2,
      "software_count":49,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2021,
      "dataset_first_created":2021,
      "dataset_last_modified":"2021-04-30"
    },
    {
      "task_id":"pan21-style-change-detection",
      "task_name":"Style Change Detection 2021",
      "task_description":"Given a document, determine the number of authors and at which positions the author changes.",
      "organizer":"PAN",
      "organizer_id":"pan",
      "web":"https://pan.webis.de/clef21/pan21-web/style-change-detection.html",
      "year":"2012-2021",
      "featured":false,
      "require_registration":false,
      "require_groups":false,
      "restrict_groups":false,
      "allowed_task_teams":"",
      "master_vm_id":"pan21-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":3,
      "software_count":25,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2021,
      "dataset_first_created":2021,
      "dataset_last_modified":"2021-04-30"
    },
    {
      "task_id":"pan22-authorship-verification",
      "task_name":"Authorship Verification 2022",
      "task_description":"Given two texts, determine if they are written by the same author.  The test dataset contains verification cases from previously unseen authors and topics.",
      "organizer":"PAN",
      "organizer_id":"pan",
      "web":"https://pan.webis.de/clef22/pan22-web/author-identification.html",
      "year":"2012-2021",
      "featured":false,
      "require_registration":false,
      "require_groups":false,
      "restrict_groups":false,
      "allowed_task_teams":"",
      "master_vm_id":"pan22-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":2,
      "software_count":80,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2022,
      "dataset_first_created":2022,
      "dataset_last_modified":"2022-05-11"
    },
    {
      "task_id":"pan22-profiling-irony-and-stereotype-spreaders-on-twitter",
      "task_name":"Profiling Irony and Stereotype Spreaders on Twitter",
      "task_description":"Task: Given a Twitter feed in English, determine whether its author spreads Irony and Stereotypes. Input: Timelines of authors sharing Irony and Stereotypes towards, for instance, women or the LGTB community. Evaluation: Accuracy.",
      "organizer":"PAN",
      "organizer_id":"pan",
      "web":"https://pan.webis.de/clef22/pan22-web/author-profiling.html",
      "year":"2012-2021",
      "featured":false,
      "require_registration":false,
      "require_groups":false,
      "restrict_groups":false,
      "allowed_task_teams":"",
      "master_vm_id":"pan22-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":2,
      "software_count":175,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"",
      "command_description":"",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2022,
      "dataset_first_created":2022,
      "dataset_last_modified":"2022-04-22"
    },
    {
      "task_id":"pan22-style-change-detection",
      "task_name":"Style Change Detection 2022",
      "task_description":"Given a document, determine the number of authors and at which positions the author changes.",
      "organizer":"PAN",
      "organizer_id":"pan",
      "web":"https://pan.webis.de/clef22/pan22-web/style-change-detection.html",
      "year":"2012-2021",
      "featured":false,
      "require_registration":false,
      "require_groups":false,
      "restrict_groups":false,
      "allowed_task_teams":"",
      "master_vm_id":"pan22-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":3,
      "software_count":76,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2022,
      "dataset_first_created":2022,
      "dataset_last_modified":"2022-04-22"
    },
    {
      "task_id":"pan23-cross-discourse-type-authorship-verification",
      "task_name":"Cross-Discourse Type Authorship Verification at PAN@CLEF 2023",
      "task_description":"Given two texts from written and oral Discourse Types (DT), determine if they are written by the same author. The datasets for this task have not been released yet. ",
      "organizer":"PAN",
      "organizer_id":"pan",
      "web":"https://pan.webis.de/clef23/pan23-web/author-identification.html",
      "year":"2012-2021",
      "featured":true,
      "require_registration":true,
      "require_groups":true,
      "restrict_groups":true,
      "allowed_task_teams":"pan23-cdav-baseline\npan23-cdav-1\npan23-cdav-2\npan23-cdav-3\npan23-cdav-4\npan23-cdav-5\npan23-cdav-6\npan23-cdav-7\npan23-cdav-8\npan23-cdav-9\npan23-cdav-10\npan23-cdav-11\npan23-cdav-12\npan23-cdav-13\npan23-cdav-14\npan23-cdav-15\npan23-cdav-16\npan23-cdav-17\npan23-cdav-18\npan23-cdav-19\npan23-cdav-20\n",
      "master_vm_id":"pan22-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":2,
      "software_count":0,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2023,
      "dataset_first_created":2023,
      "dataset_last_modified":"2023-03-22"
    },
    {
      "task_id":"pan23-multi-author-writing-style-analysis",
      "task_name":"Multi-Author Writing Style Analysis at PAN@CLEF 2023",
      "task_description":"Given a document, determine at which positions the author changes. The datasets for this task have not been released yet. ",
      "organizer":"PAN",
      "organizer_id":"pan",
      "web":"https://pan.webis.de/clef23/pan23-web/style-change-detection.html",
      "year":"2012-2021",
      "featured":true,
      "require_registration":true,
      "require_groups":true,
      "restrict_groups":true,
      "allowed_task_teams":"pan23-mawsa-baseline\npan23-mawsa-1\npan23-mawsa-2\npan23-mawsa-3\npan23-mawsa-4\npan23-mawsa-5\npan23-mawsa-6\npan23-mawsa-7\npan23-mawsa-8\npan23-mawsa-9\npan23-mawsa-10\npan23-mawsa-11\npan23-mawsa-12\npan23-mawsa-13\npan23-mawsa-14\npan23-mawsa-15\npan23-mawsa-16\npan23-mawsa-17\npan23-mawsa-18\npan23-mawsa-19\npan23-mawsa-20",
      "master_vm_id":"pan22-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":9,
      "software_count":0,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2023,
      "dataset_first_created":2023,
      "dataset_last_modified":"2023-03-22"
    },
    {
      "task_id":"pan23-profiling-cryptocurrency-influencers-with-few-shot-learning",
      "task_name":"Profiling Cryptocurrency Influencers with Few-shot Learning at PAN@CLEF 2023",
      "task_description":"In this shared task we aim to profile cryptocurrency influencers in social media, from a low-resource perspective. Moreover, we propose to categorize other related aspects of the influencers, also using a low-resource setting.",
      "organizer":"PAN",
      "organizer_id":"pan",
      "web":"https://pan.webis.de/clef23/pan23-web/author-profiling.html",
      "year":"2012-2021",
      "featured":true,
      "require_registration":true,
      "require_groups":true,
      "restrict_groups":true,
      "allowed_task_teams":"pan23-symanto\nsymanto\npan23-bitcoin\npan23-ethereum\npan23-tether\npan23-bnb\npan23-usd-coin\npan23-xrp\npan23-cardano\npan23-dogecoin\npan23-polygon\npan23-solana\npan23-binance-usd\npan23-polkadot\npan23-litecoin\npan23-shiba-inu\npan23-tron\npan23-avalanche\npan23-dai\npan23-uniswap\npan23-chainlink\npan23-cosmos\npan23-unus-sed-leo\npan23-toncoin\npan23-monero\npan23-okb\npan23-stellar\npan23-filecoin\npan23-aptos\npan23-trueusd\npan23-lido-dao\npan23-hedera\npan23-cronos\npan23-near-protocol\npan23-vechain\npan23-stacks\npan23-algorand\npan23-quant\npan23-internet-computer\npan23-apecoin\npan23-the-graph\npan23-fantom\npan23-eos\npan23-bitdao\npan23-decentraland\npan23-aave\npan23-multiversx\npan23-tezos\npan23-immutable\npan23-flow\npan23-conflux\npan23-theta-network\npan23-axie-infinity\npan23-the-sandbox\npan23-kucoin-token\npan23-pax-dollar\npan23-neo\npan23-chiliz\npan23-optimism\npan23-rocket-pool\npan23-terra-classic\npan23-usdd\npan23-mina\npan23-curve-dao-token\npan23-klaytn\npan23-synthetix\npan23-pancakeswap\npan23-maker\npan23-gmx\npan23-dash\npan23-gemini-dollar\npan23-singularitynet\npan23-ecash\npan23-frax-share\npan23-huobi-token\npan23-iota\npan23-zcash\npan23-gatetoken\npan23-xdc-network\npan23-pax-gold\npan23-trust-wallet-token\npan23-render-token\npan23-loopring\npan23-thorchain\npan23-zilliqa\npan23-1inch-network\npan23-fei-usd\npan23-convex-finance\npan23-mask-network\npan23-osmosis\npan23-kava\npan23-casper\npan23-enjin-coin\npan23-dydx\npan23-nexo\npan23-flare\npan23-magic\npan23-ethereumpow\npan23-threshold\npan23-basic-attention-token\npan23-ssv.network\npan23-nem\npan23-woo-network\npan23-qtum\npan23-floki\npan23-terra\npan23-oasis-network\npan23-ravencoin\npan23-ankr\npan23-theta-fuel\npan23-balancer\npan23-compound\npan23-holo\npan23-fetch.ai\npan23-yearn.finance\npan23-injective\npan23-celo\npan23-mobilecoin\npan23-harmony\npan23-decred\npan23-gala\npan23-kusama\npan23-arweave\npan23-gnosis\npan23-astar\npan23-audius\npan23-link\npan23-chia\npan23-blur\npan23-omg-network\npan23-waves\npan23-sushiswap\npan23-golem\npan23-nervos-network\npan23-stepn\npan23-iotex\npan23-moonbeam\npan23-just\npan23-jasmycoin\npan23-kadena\npan23-ocean-protocol\npan23-dao-maker\npan23-siacoin\npan23-terraclassicusd\npan23-band-protocol\npan23-liquity\npan23-icon\npan23-iost\npan23-mx-token\npan23-ontology\npan23-symbol\npan23-biconomy\npan23-0x\npan23-dogelon-mars\npan23-hive\npan23-bitgert\npan23-livepeer\npan23-swissborg\npan23-flux\npan23-alchemy-pay\npan23-celer-network\npan23-reserve-rights\npan23-aelf\npan23-keep-network\npan23-bora\npan23-iexec-rlc\npan23-helium\npan23-polymath\npan23-wax\npan23-safepal\npan23-skale\npan23-amp\npan23-binaryx\npan23-illuvium\npan23-space-id\npan23-everscale\npan23-digibyte\npan23-solar\npan23-storj\npan23-core\npan23-uma\npan23-multichain\npan23-horizen\npan23-gitcoin\npan23-lisk\npan23-syscoin\npan23-synapse\npan23-api3\npan23-braintrust\npan23-axelar\npan23-joe\npan23-origintrail\npan23-tribe",
      "master_vm_id":"pan22-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":6,
      "software_count":0,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2023,
      "dataset_first_created":2023,
      "dataset_last_modified":"2023-02-10"
    },
    {
      "task_id":"pan23-trigger-detection",
      "task_name":"Trigger Detection at PAN@CLEF 2023",
      "task_description":"Given a document, assign all appropriate trigger warning labels.",
      "organizer":"PAN",
      "organizer_id":"pan",
      "web":"https://pan.webis.de/clef23/pan23-web/trigger-detection.html",
      "year":"2012-2021",
      "featured":true,
      "require_registration":true,
      "require_groups":true,
      "restrict_groups":true,
      "allowed_task_teams":"trigger-detection-baseline\npan23-harry-potter\npan23-good-omens\npan23-wiedzmin\npan23-star-wars\npan23-batman\npan23-les-miserables\npan23-marvel-cinematic-universe\npan23-the-avengers\npan23-captain-america\npan23-iron-man\npan23-thor\npan23-transformers\npan23-spider-man\npan23-arrow\npan23-captain-america\npan23-sherlock\npan23-supernatural\npan23-game-of-thrones\npan23-once-upon-a-time\npan23-teen-wolf\npan23-doctor-who\npan23-merlin\npan23-glee\npan23-supergirl\npan23-shadowhunters\npan23-stargate-sg-1\npan23-buffy-the-vampire-slayer\npan23-stranger-things\npan23-the-walking-dead\npan23-torchwood\npan23-critical-role\npan23-mo-dao-zu-shi\npan23-boku-no-hero-academia\npan23-haikyuu\npan23-naruto\npan23-shingeki-no-kyojin\npan23-miraculous-ladybug\npan23-jojo-no-kimyou-na-bouken\npan23-hetalia\npan23-yuri-on-ice\npan23-kuroko-no-basuke\npan23-bleach\npan23-gravity-falls\npan23-voltron\npan23-homestuck\npan23-hamilton\npan23-bangtan-boys\npan23-nct\npan23-exo\npan23-stray-kids\npan23-one-direction\npan23-minecraft\npan23-undertale\npan23-overwatch\npan23-genshin-impact\npan23-dragon-age\npan23-dangan-ronpa\npan23-persona-5\npan23-pokemon",
      "master_vm_id":"pan22-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":3,
      "software_count":0,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -i $inputDataset -o $outputDir",
      "command_description":"Available variables: \n  \u003Ccode\u003E$inputDataset\u003C/code\u003E - this resolves to the directory that contains the works.jsonl.\n  \u003Ccode\u003E$outputDir\u003C/code\u003E - this resolves to the directory where the labels.jsonl should be written to. ",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2023,
      "dataset_first_created":2023,
      "dataset_last_modified":"2023-02-10"
    },
    {
      "task_id":"product-line-sampling",
      "task_name":"Product Line Sampling",
      "task_description":"Given product line and its features, sample products to satisfy least coverage criteria.",
      "organizer":"SPLC",
      "organizer_id":"splc",
      "web":"https://variability-challenges.github.io/2019/Sampling/index.html",
      "year":"2019",
      "featured":false,
      "require_registration":false,
      "require_groups":false,
      "restrict_groups":false,
      "allowed_task_teams":"",
      "master_vm_id":"splc19-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":10,
      "software_count":11,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2019,
      "dataset_first_created":2012,
      "dataset_last_modified":"2012-01-01"
    },
    {
      "task_id":"scai-qrecc",
      "task_name":"SCAI QReCC Conversational Question Answering Challenge",
      "task_description":"Conversational Question Answering (CQA) is one of the core applications for retrieval-based chatbots. In CQA, the task is to answer a series of contextually-dependent questions like they may occur in natural human-to-human conversations.",
      "organizer":"SCAI",
      "organizer_id":"scai",
      "web":"https://scai.info/scai-qrecc/",
      "year":"2021",
      "featured":false,
      "require_registration":false,
      "require_groups":false,
      "restrict_groups":false,
      "allowed_task_teams":"",
      "master_vm_id":"scai-qrecc21-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":8,
      "software_count":127,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -i $inputDataset -o $outputDir",
      "command_description":"Your software has to read \u003Ccode\u003E$inputDataset/question.json\u003C/code\u003E and write to \u003Ccode\u003E$outputDir/run.json\u003C/code\u003E \u003Ca href=\"https://github.com/scai-conf/SCAI-QReCC-21#software-submission\" target=\"_blank\"\u003E[detailed instructions]\u003C/a\u003E",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2022,
      "dataset_first_created":2021,
      "dataset_last_modified":"2021-05-15"
    },
    {
      "task_id":"shallow-discourse-parsing",
      "task_name":"Shallow Discourse Parsing",
      "task_description":"Given a piece of newswire text, your task is to identify explicit and implicit discourse relations. The task is available in both Chinese and English in 2016.",
      "organizer":"CoNLL",
      "organizer_id":"conll",
      "web":"http://www.cs.brandeis.edu/~clp/conll15st/",
      "year":"2015-2018",
      "featured":false,
      "require_registration":false,
      "require_groups":false,
      "restrict_groups":false,
      "allowed_task_teams":"",
      "master_vm_id":"conll15-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":20,
      "software_count":164,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":100,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2016,
      "dataset_first_created":2015,
      "dataset_last_modified":"2015-03-04"
    },
    {
      "task_id":"source-retrieval",
      "task_name":"Source Retrieval",
      "task_description":"Given a suspicious document and a web search API, your task is to retrieve all plagiarized sources while minimizing retrieval costs.",
      "organizer":"PAN",
      "organizer_id":"pan",
      "web":"http://pan.webis.de",
      "year":"2012-2021",
      "featured":false,
      "require_registration":false,
      "require_groups":false,
      "restrict_groups":false,
      "allowed_task_teams":"",
      "master_vm_id":"pan15-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":4,
      "software_count":78,
      "max_std_out_chars_on_test_data":1000,
      "max_std_err_chars_on_test_data":1000,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2014,
      "dataset_first_created":2014,
      "dataset_last_modified":"2014-04-22"
    },
    {
      "task_id":"style-breach-detection",
      "task_name":"Style Change Detection",
      "task_description":"Given a document, determine whether it is multi-authored, and if yes, find the borders where authors switch.",
      "organizer":"PAN",
      "organizer_id":"pan",
      "web":"http://pan.webis.de",
      "year":"2012-2021",
      "featured":false,
      "require_registration":false,
      "require_groups":false,
      "restrict_groups":false,
      "allowed_task_teams":"",
      "master_vm_id":"pan15-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":11,
      "software_count":54,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2020,
      "dataset_first_created":2017,
      "dataset_last_modified":"2017-02-15"
    },
    {
      "task_id":"text-alignment",
      "task_name":"Text Alignment",
      "task_description":"Given a pair of documents, your task is to identify all contiguous maximal-length passages of reused text between them.",
      "organizer":"PAN",
      "organizer_id":"pan",
      "web":"http://pan.webis.de",
      "year":"2012-2021",
      "featured":false,
      "require_registration":false,
      "require_groups":false,
      "restrict_groups":false,
      "allowed_task_teams":"",
      "master_vm_id":"pan15-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":43,
      "software_count":112,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2017,
      "dataset_first_created":2013,
      "dataset_last_modified":"2014-04-22"
    },
    {
      "task_id":"tira-tutorial-ir-task",
      "task_name":"tira-tutorial-ir-task",
      "task_description":"This is my tutorial",
      "organizer":"tira-tutorial",
      "organizer_id":"tira-tutorial",
      "web":"",
      "year":"2023",
      "featured":false,
      "require_registration":false,
      "require_groups":false,
      "restrict_groups":false,
      "allowed_task_teams":"",
      "master_vm_id":"princess-knight",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":1,
      "software_count":0,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2023,
      "dataset_first_created":2023,
      "dataset_last_modified":"2023-04-10"
    },
    {
      "task_id":"tldr-generation",
      "task_name":"Abstractive Summarization",
      "task_description":"Given a social media post, generate its summary.",
      "organizer":"INLG",
      "organizer_id":"inlg",
      "web":"https://events.webis.de/tldr-19/",
      "year":"2019",
      "featured":false,
      "require_registration":false,
      "require_groups":false,
      "restrict_groups":false,
      "allowed_task_teams":"",
      "master_vm_id":"inlg19-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":3,
      "software_count":22,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2018,
      "dataset_first_created":2018,
      "dataset_last_modified":"2018-11-05"
    },
    {
      "task_id":"touche-2023-task-2",
      "task_name":"Evidence Retrieval for Causal Questions",
      "task_description":"Given a causality-related topic, the task is to retrieve and rank documents by relevance to the topic and detect the document \"causal\" stance.",
      "organizer":"Touch\u00e9",
      "organizer_id":"touche",
      "web":"https://touche.webis.de/",
      "year":"2020-2022",
      "featured":true,
      "require_registration":true,
      "require_groups":true,
      "restrict_groups":true,
      "allowed_task_teams":"touche23-bayek-of-siwa\ntouche23-baseline\ntouche23-puss-in-boots\ntouche23-beatrix-kiddo\ntouche23-cavalier\ntouche23-ebon-samurai\ntouche23-el-aguila\ntouche23-elloe-kaifi\ntouche23-faiza-hussain\ntouche23-fandral\ntouche23-feanor\ntouche23-gin-ichimaru\ntouche23-goldar\ntouche23-gourry-gabriev\ntouche23-hector-barbossa\ntouche23-hikaru-sulu\ntouche23-hiroim\ntouche23-khal-drogo\ntouche23-kitsuru-kirijo\ntouche23-princess-knight\ntouche23-queen-of-swords\ntouche23-red-sonja\ntouche23-renji-abarai\ntouche23-saber-rider\ntouche23-silver-surfer\ntouche23-the-bride\ntouche23-yuno-gasai\ntouche23-test-maik\ntouche23-test-ferdi\ntouche23-test-theresa\ntouche23-test-simon\ntouche23-neville-longbottom\ntouche23-jean-luc-picard\ntouche23-he-man\ntouche23-zorro\ntouche23-don-quixote",
      "master_vm_id":"touche-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"webis/tira-application:0.0.36",
      "irds_re_ranking_command":"/irds_cli.sh --input_dataset_directory $inputDataset --output_dataset_path $outputDir --rerank $inputRun",
      "irds_re_ranking_resource":"irds-data-mounted",
      "dataset_count":1,
      "software_count":0,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -i $inputDataset -o $outputDir",
      "command_description":"Commands should take the arguments \u003Ccode\u003E$inputDataset\u003C/code\u003E and \u003Ccode\u003E$outputDir\u003C/code\u003E. The variable \u003Ccode\u003E$inputDataset\u003C/code\u003E points to a directory that contains the input collection, including the \u003Ccode\u003Etopics.xml\u003C/code\u003E that contains the topics for which images should be retrieved. Your software should create a standard trec run file in \u003Ccode\u003E$outputDir/run.txt\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2023,
      "dataset_first_created":2023,
      "dataset_last_modified":"2023-02-27"
    },
    {
      "task_id":"touche-2023-task-4",
      "task_name":"Intra-Multilingual Multi-Target Stance Classification",
      "task_description":"Given a proposal on a socially important issue, the task is to classify whether a comment is in favor, against, or neutral towards the proposal.",
      "organizer":"Touch\u00e9",
      "organizer_id":"touche",
      "web":"https://touche.webis.de/clef23/touche23-web/multilingual-stance-classification.html",
      "year":"2020-2022",
      "featured":true,
      "require_registration":true,
      "require_groups":true,
      "restrict_groups":true,
      "allowed_task_teams":"touche23-baseline\ntouche23-bayek-of-siwa\ntouche23-cavalier\ntouche23-ebon-samurai\ntouche23-beatrix-kiddo\ntouche23-el-aguila\ntouche23-elloe-kaifi\ntouche23-faiza-hussain\ntouche23-fandral\ntouche23-feanor\ntouche23-gin-ichimaru\ntouche23-goldar\ntouche23-gourry-gabriev\ntouche23-hector-barbossa\ntouche23-hikaru-sulu\ntouche23-hiroim\ntouche23-khal-drogo\ntouche23-kitsuru-kirijo\ntouche23-princess-knight\ntouche23-queen-of-swords\ntouche23-red-sonja\ntouche23-renji-abarai\ntouche23-saber-rider\ntouche23-silver-surfer\ntouche23-the-bride\ntouche23-yuno-gasai\ntouche23-neville-longbottom\ntouche23-jean-luc-picard\ntouche23-he-man\ntouche23-zorro",
      "master_vm_id":"touche-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":2,
      "software_count":0,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -i $inputDataset -o $outputDir",
      "command_description":"Commands should take the arguments \u003Ccode\u003E$inputDataset\u003C/code\u003E and \u003Ccode\u003E$outputDir\u003C/code\u003E. The variable \u003Ccode\u003E$inputDataset\u003C/code\u003E points to a directory that contains a \u003Ccode\u003Etopics.xml\u003C/code\u003E file that contains the topics for which documents should be retrieved and a file \u003Ccode\u003Epassages.jsonl.gz\u003C/code\u003E that contains all the passages. Your software should create a standard trec run file in \u003Ccode\u003E$outputDir/run.txt\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2023,
      "dataset_first_created":2022,
      "dataset_last_modified":"2023-01-03"
    },
    {
      "task_id":"touche-task-1",
      "task_name":"Argument Retrieval for Controversial Questions",
      "task_description":"Retrieval in a focused argument collection to support argumentative conversations.",
      "organizer":"Touch\u00e9",
      "organizer_id":"touche",
      "web":"https://touche.webis.de/",
      "year":"2020-2022",
      "featured":true,
      "require_registration":true,
      "require_groups":true,
      "restrict_groups":true,
      "allowed_task_teams":"touche23-bayek-of-siwa\ntouche23-cavalier\ntouche23-beatrix-kiddo\ntouche23-don-quixote\ntouche23-ebon-samurai\ntouche23-el-aguila\ntouche23-elloe-kaifi\ntouche23-faiza-hussain\ntouche23-fandral\ntouche23-feanor\ntouche23-gin-ichimaru\ntouche23-goldar\ntouche23-gourry-gabriev\ntouche23-hector-barbossa\ntouche23-hikaru-sulu\ntouche23-hiroim\ntouche23-khal-drogo\ntouche23-kitsuru-kirijo\ntouche23-princess-knight\ntouche23-queen-of-swords\ntouche23-red-sonja\ntouche23-renji-abarai\ntouche23-saber-rider\ntouche23-silver-surfer\ntouche23-the-bride\ntouche23-yuno-gasai\ntouche23-neville-longbottom\ntouche23-jean-luc-picard\ntouche23-he-man\ntouche23-zorro",
      "master_vm_id":"touche-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":3,
      "software_count":358,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -i $inputDataset -o $outputDir",
      "command_description":"Commands should take the arguments \u003Ccode\u003E$inputDataset\u003C/code\u003E and \u003Ccode\u003E$outputDir\u003C/code\u003E. The variable \u003Ccode\u003E$inputDataset\u003C/code\u003E points to a directory which contains the corpus: \u003Ccode\u003Eargs_processed_04_01.csv\u003C/code\u003E (and its compressed version \u003Ccode\u003Eargs_processed_04_01.tar.gz\u003C/code\u003E), and \u003Ccode\u003Etopics.xml\u003C/code\u003E (the topics for which documents should retrieved). Your software should create a standard trec run file in \u003Ccode\u003E$outputDir/run.txt\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2022,
      "dataset_first_created":2020,
      "dataset_last_modified":"2021-04-30"
    },
    {
      "task_id":"touche-task-2",
      "task_name":"Argument Retrieval for Comparative Questions",
      "task_description":"Retrieval in a generic web crawl to answer comparative questions with argumentative results.",
      "organizer":"Touch\u00e9",
      "organizer_id":"touche",
      "web":"https://touche.webis.de/",
      "year":"2020-2022",
      "featured":false,
      "require_registration":false,
      "require_groups":false,
      "restrict_groups":false,
      "allowed_task_teams":"",
      "master_vm_id":"touche-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":3,
      "software_count":101,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -i $inputDataset -o $outputDir",
      "command_description":"Commands should take the arguments \u003Ccode\u003E$inputDataset\u003C/code\u003E and \u003Ccode\u003E$outputDir\u003C/code\u003E. The variable \u003Ccode\u003E$inputDataset\u003C/code\u003E points to a directory that contains a \u003Ccode\u003Etopics.xml\u003C/code\u003E file that contains the topics for which documents should be retrieved and a file \u003Ccode\u003Epassages.jsonl.gz\u003C/code\u003E that contains all the passages. Your software should create a standard trec run file in \u003Ccode\u003E$outputDir/run.txt\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2022,
      "dataset_first_created":2020,
      "dataset_last_modified":"2021-04-30"
    },
    {
      "task_id":"touche-task-3",
      "task_name":"Image Retrieval for Arguments",
      "task_description":"Given a controversial topic, the task is to retrieve images (from web pages) for each stance (pro/con) that show support for that stance.",
      "organizer":"Touch\u00e9",
      "organizer_id":"touche",
      "web":"https://touche.webis.de/",
      "year":"2020-2022",
      "featured":true,
      "require_registration":true,
      "require_groups":true,
      "restrict_groups":true,
      "allowed_task_teams":"touche23-bayek-of-siwa\ntouche23-cavalier\ntouche23-maik-froebe-query-submissions\ntouche23-ebon-samurai\ntouche23-el-aguila\ntouche23-elloe-kaifi\ntouche23-faiza-hussain\ntouche23-fandral\ntouche23-beatrix-kiddo\ntouche23-feanor\ntouche23-gin-ichimaru\ntouche23-goldar\ntouche23-gourry-gabriev\ntouche23-hector-barbossa\ntouche23-hikaru-sulu\ntouche23-hiroim\ntouche23-khal-drogo\ntouche23-kitsuru-kirijo\ntouche23-princess-knight\ntouche23-queen-of-swords\ntouche23-red-sonja\ntouche23-renji-abarai\ntouche23-saber-rider\ntouche23-silver-surfer\ntouche23-the-bride\ntouche23-yuno-gasai\nminsc\ntouche23-neville-longbottom\ntouche23-jean-luc-picard\ntouche23-he-man\ntouche23-zorro",
      "master_vm_id":"touche-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":4,
      "software_count":27,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -i $inputDataset -o $outputDir",
      "command_description":"Commands should take the arguments \u003Ccode\u003E$inputDataset\u003C/code\u003E and \u003Ccode\u003E$outputDir\u003C/code\u003E. The variable \u003Ccode\u003E$inputDataset\u003C/code\u003E points to a directory that contains the input collection, including the \u003Ccode\u003Etopics.xml\u003C/code\u003E that contains the topics for which images should be retrieved. Your software should create a standard trec run file in \u003Ccode\u003E$outputDir/run.txt\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2023,
      "dataset_first_created":2022,
      "dataset_last_modified":"2023-04-12"
    },
    {
      "task_id":"triple-scoring",
      "task_name":"Triple Scoring",
      "task_description":"Given a triple from a \"type-like\" relation, compute a score that measures the relevance of the statement expressed by the triple compared to other triples from the same relation.",
      "organizer":"WSDM Cup",
      "organizer_id":"wsdm-cup",
      "web":"http://www.wsdm-cup-2017.org",
      "year":"2017",
      "featured":false,
      "require_registration":false,
      "require_groups":false,
      "restrict_groups":false,
      "allowed_task_teams":"",
      "master_vm_id":"wsdmcup17-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":4,
      "software_count":131,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2016,
      "dataset_first_created":2016,
      "dataset_last_modified":"2016-11-10"
    },
    {
      "task_id":"universal-dependency-learning",
      "task_name":"Universal Dependency Learning",
      "task_description":"The task is learning syntactic dependency parsers that can work in a real-world setting, starting from raw text, and that can work over many typologically different languages, even surprise languages for which there is little or no training data, by exploiting a common syntactic annotation standard.",
      "organizer":"CoNLL",
      "organizer_id":"conll",
      "web":"http://universaldependencies.org/conll18/",
      "year":"2015-2018",
      "featured":false,
      "require_registration":false,
      "require_groups":false,
      "restrict_groups":false,
      "allowed_task_teams":"",
      "master_vm_id":"conll17-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":10,
      "software_count":209,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -c $inputDataset -r $inputRun -o $outputDir",
      "command_description":"Available variables: \u003Ccode\u003E$inputDataset\u003C/code\u003E, \u003Ccode\u003E$inputRun\u003C/code\u003E, \u003Ccode\u003E$outputDir\u003C/code\u003E, \u003Ccode\u003E$dataServer\u003C/code\u003E, and \u003Ccode\u003E$token\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":65536,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2018,
      "dataset_first_created":2017,
      "dataset_last_modified":"2017-05-09"
    },
    {
      "task_id":"valueeval-at-semeval-2023-human-value-detection",
      "task_name":"ValueEval at SemEval 2023 - Human Value Detection",
      "task_description":"Given a textual argument and a human value category, classify whether or not the argument draws on that category.",
      "organizer":"Touch\u00e9",
      "organizer_id":"touche",
      "web":"https://valueeval.webis.de",
      "year":"2020-2022",
      "featured":false,
      "require_registration":true,
      "require_groups":true,
      "restrict_groups":true,
      "allowed_task_teams":"aristotle\ntouche23-samuel-bailey\ntouche23-francis-bacon\ntouche23-johann-georg-walch\ntouche23-joseph-fletcher\ntouche23-niccolo-machiavellie\ntouche23-james-mill\ntouche23-lauri-ingman\ntouche23-andronicus-of-rhodes\ntouche23-iris-murdoch\ntouche23-john-arthur\ntouche23-hsun-tzu\ntouche23-tenzin-gyatso\ntouche23-georg-simmel\ntouche23-norman-daniels\ntouche23-bertrand-russell\ntouche23-michael-j-sandel\ntouche23-tadeusz-kotarbinski\ntouche23-tess-posner\ntouche23-fazlur-rahman\ntouche23-roger-chao\ntouche23-menedemus\naugustine-of-hippo\ntouche23-ambrose\ntouche23-murray-bookchin\ntouche23-thiruvalluvar\ntouche23-francisco-de-vitoria\ntouche23-rudolf-christoph-eucken\ntouche23-t-m-scanlon\ntouche23-george-boole\ntouche23-aristoxenus\nkarl-immanuel-nitzsch\ntouche23-ashoka\ntouche23-stanley-grenz\ntouche23-adam-smith\ntouche23-albert-camus\ntouche23-albert-schweitzer\ntouche23-ambedkar\ntouche23-swami-vivekananda\ntouche23-tom-regan\ntouche23-confucius\ntouche23-david-pearce\ntouche23-epicurus\ntouche23-friedrich-nietzsche\ntouche23-gautama-buddha\ntouche23-glenn-mc-gee\ntouche23-hammurabi\ntouche23-blaise-pascal\ntouche23-immanuel-kant\ntouche23-jesus-of-nazareth\ntouche23-johann-friedrich-herbart\ntouche23-xunzi-kuang\ntouche23-john-locke\ntouche23-john-paul-ii\ntouche23-juergen-habermas\ntouche23-julia-driver\ntouche23-leo-tolstoy\ntouche23-mao-zedong\ntouche23-marquis-de-sade\ntouche23-mary-daly\ntouche23-martha-nussbaum\ntouche23-david-gauthier\ntouche23-mohandas-gandhi\ntouche23-noam-chomsky\ntouche23-philippa-foot\ntouche23-quintilian\ntouche23-robert-s-hartman\ntouche23-sun-yat-sen\ntouche23-xenocrates\ntouche23-theodor-zwinger\ntouche23-xun-kuang\ntouche23-plato\ntouche23-r-m-hare\ntouche23-prodicus\ntouche23-soren-kierkegaard\ntouche23-arthur-caplan\ntouche23-zoroaster\ntouche23-xunzi-kuang\ntouche23-seyyed-hossein-nasr\ntouche23-mencius\ntouche23-rushworth-kidder\ntouche23-ronald-dworkin\ntouche23-mozi\ntouche23-al-ghazali\ntouche23-victor-gollancz\ntouche23-martin-luther-king-jr",
      "master_vm_id":"princess-knight",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":7,
      "software_count":0,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware --input $inputDataset/arguments.tsv --output $outputDir/predictions.tsv",
      "command_description":"Your software is expected to read a tab-separated values files in \u003Ccode\u003E$inputDataset\u003C/code\u003E and produce a predictions file in \u003Ccode\u003E$outputDir\u003C/code\u003E.",
      "dataset_label":"Input dataset",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2023,
      "dataset_first_created":2022,
      "dataset_last_modified":"2023-01-19"
    },
    {
      "task_id":"vandalism-detection",
      "task_name":"Vandalism Detection",
      "task_description":"Given a Wikidata revision, compute a vandalism score denoting the likelihood of this revision beeing vandalism (or similarly damaging).",
      "organizer":"WSDM Cup",
      "organizer_id":"wsdm-cup",
      "web":"http://www.wsdm-cup-2017.org",
      "year":"2017",
      "featured":false,
      "require_registration":false,
      "require_groups":false,
      "restrict_groups":false,
      "allowed_task_teams":"",
      "master_vm_id":"wsdmcup17-master",
      "is_ir_task":false,
      "irds_re_ranking_image":"",
      "irds_re_ranking_command":"",
      "irds_re_ranking_resource":"",
      "dataset_count":5,
      "software_count":56,
      "max_std_out_chars_on_test_data":0,
      "max_std_err_chars_on_test_data":0,
      "max_file_list_chars_on_test_data":0,
      "command_placeholder":"mySoftware -s $dataServer",
      "command_description":"Commands must take \u003Ccode\u003E$dataServer\u003C/code\u003E and \u003Ccode\u003E$accessToken\u003C/code\u003E, which are replaced with \u0026lt;hostname\u0026gt;:\u0026lt;port\u0026gt; and an access token to access the server.\u003Cbr\u003ECommands may take \u003Ccode\u003E$outputDir\u003C/code\u003E and \u003Ccode\u003E$inputRun\u003C/code\u003E, which will point to paths.\u003Cbr\u003E\u003Cbr\u003EExample commands:\u003Cbr\u003E- Test software with pre-trained models: \u003Ccode\u003EmySoftware -c $dataServer -t $accessToken\u003C/code\u003E\u003Cbr\u003E- Test software without pre-trained models: \u003Ccode\u003EmySoftware -c $dataServer -t $accessToken -r $inputRun\u003C/code\u003E, where \u003Ccode\u003E$inputRun\u003C/code\u003E is the run of a training software comprising trained models.\u003Cbr\u003E- Training software to train models: \u003Ccode\u003EmySoftware -i $inputDataset -o $outputDir\u003C/code\u003E, which train based on a training dataset (\u003Ccode\u003E$inputDataset\u003C/code\u003E) and write trained models to \u003Ccode\u003E$outputDir\u003C/code\u003E.",
      "dataset_label":"Data server",
      "max_std_out_chars_on_test_data_eval":0,
      "max_std_err_chars_on_test_data_eval":0,
      "max_file_list_chars_on_test_data_eval":0,
      "dataset_last_created":2016,
      "dataset_first_created":2016,
      "dataset_last_modified":"2016-10-12"
    }
  ]
}